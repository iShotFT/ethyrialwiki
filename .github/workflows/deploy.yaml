name: Deploy

on:
  workflow_dispatch:
    inputs:
      environment:
        description: "Target environment"
        required: true
        type: choice
        options:
          - staging
          - production
      version:
        description: "Version to deploy (default: latest)"
        required: false
        default: "latest"
        type: string
      use_latest_image:
        description: "Use latest image regardless of version"
        required: false
        default: false
        type: boolean
      services:
        description: "Services to deploy (comma-separated, default: all)"
        required: false
        default: "all"
        type: string

env:
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
  REGISTRY: ghcr.io
  IMAGE_NAME_BASE: ishotft/ethyrialwiki

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment }}

    steps:
      - uses: actions/checkout@v4

      - name: Install kubectl
        uses: azure/setup-kubectl@v3

      - name: Configure kubectl
        run: |
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > $HOME/.kube/config
          chmod 600 $HOME/.kube/config

      - name: Install Helm
        uses: azure/setup-helm@v3
        with:
          version: "latest"

      - name: Set version
        id: version
        run: |
          VERSION="${{ github.event.inputs.version }}"
          USE_LATEST="${{ github.event.inputs.use_latest_image }}"

          if [ "$VERSION" = "latest" ] || [ "$USE_LATEST" = "true" ]; then
            echo "Using latest image tag"
            VERSION="latest"
          fi

          echo "version=$VERSION" >> $GITHUB_OUTPUT

      - name: Parse services
        id: services
        run: |
          SERVICES="${{ github.event.inputs.services }}"
          if [ "$SERVICES" = "all" ]; then
            SERVICES="web,worker,collaboration"
          fi
          # Remove any trailing commas that might cause Helm issues
          SERVICES=$(echo $SERVICES | sed 's/,$//')
          echo "services=$SERVICES" >> $GITHUB_OUTPUT

      - name: Set namespace
        id: namespace
        run: |
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          NAMESPACE="ethyrial-$ENVIRONMENT"
          echo "namespace=$NAMESPACE" >> $GITHUB_OUTPUT

      - name: Run pre-deployment script
        run: |
          chmod +x ./k3s-migration/pre-deploy.sh
          ./k3s-migration/pre-deploy.sh

      - name: Build Helm dependencies
        run: |
          helm dependency build ./deploy/helm/outline

      - name: Deploy to Kubernetes
        run: |
          VERSION=${{ steps.version.outputs.version }}
          SERVICES=${{ steps.services.outputs.services }}
          NAMESPACE=${{ steps.namespace.outputs.namespace }}

          # Split services into individual --set parameters
          SERVICE_PARAMS=""
          IFS=',' read -ra SERVICE_ARRAY <<< "$SERVICES"
          for service in "${SERVICE_ARRAY[@]}"; do
            SERVICE_PARAMS="$SERVICE_PARAMS --set services.$service=true"
          done

          # Create the namespace if it doesn't exist
          kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

          # Use a better approach for updates - don't delete existing deployments first
          # This allows Kubernetes to perform proper rolling updates

          # Special handling for production environment to avoid PVC issues
          if [[ "$NAMESPACE" == "ethyrial-production" ]]; then
            echo "Checking for existing PVC in production..."
            if kubectl get pvc outline-data -n $NAMESPACE &>/dev/null; then
              PVC_SIZE=$(kubectl get pvc outline-data -n $NAMESPACE -o jsonpath='{.status.capacity.storage}')
              echo "Found existing PVC with size $PVC_SIZE"
              
              echo "Using existingClaim for PVC in production..."
              HELM_ARGS="--set persistence.existingClaim=outline-data"
            else
              echo "No existing PVC found, using standard deployment..."
              HELM_ARGS=""
            fi
          else
            # Standard deployment for non-production environments
            HELM_ARGS=""
          fi

          # Perform Helm upgrade with proper update strategy
          echo "Deploying with rolling update strategy for zero downtime..."
          helm upgrade --install outline ./deploy/helm/outline \
            --namespace $NAMESPACE \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME_BASE }} \
            --set image.tag=$VERSION \
            --set environment=${{ github.event.inputs.environment }} \
            $SERVICE_PARAMS \
            $HELM_ARGS \
            --set ingress.host=${{ github.event.inputs.environment == 'production' && 'ethyrial.wiki' || 'staging.ethyrial.wiki' }} \
            --values ./deploy/helm/outline/values-${{ github.event.inputs.environment }}.yaml \
            --timeout 10m

      - name: Verify deployment
        run: |
          NAMESPACE=${{ steps.namespace.outputs.namespace }}

          # Wait for web deployment with a timeout
          echo "Waiting for web deployment to be ready..."
          kubectl rollout status deployment/outline-web -n $NAMESPACE --timeout=300s

          # Only check other components if they were deployed
          if [[ "${{ steps.services.outputs.services }}" == *"worker"* ]]; then
            echo "Waiting for worker deployment to be ready..."
            kubectl rollout status deployment/outline-worker -n $NAMESPACE --timeout=300s
          fi

          if [[ "${{ steps.services.outputs.services }}" == *"collaboration"* ]]; then
            echo "Waiting for collaboration deployment to be ready..."
            kubectl rollout status deployment/outline-collaboration -n $NAMESPACE --timeout=300s
          fi

          echo "Deployment verification completed"

      - name: Output Nginx Proxy Manager Settings
        run: |
          NAMESPACE=${{ steps.namespace.outputs.namespace }}
          HOST=${{ github.event.inputs.environment == 'production' && 'ethyrial.wiki' || 'staging.ethyrial.wiki' }}

          echo "::group::Nginx Proxy Manager Settings for $HOST"
          echo "=================================="
          echo "NGINX PROXY MANAGER CONFIGURATION"
          echo "=================================="
          echo
          echo "Domain: $HOST"
          echo "Scheme: https"

          # Get ingress controller pod IP (preferred method)
          INGRESS_POD_IP=$(kubectl get pods -n ingress-nginx -o jsonpath='{.items[0].status.podIP}')
          if [ -n "$INGRESS_POD_IP" ]; then
            echo "Forward Hostname/IP: $INGRESS_POD_IP"
            echo "Forward Port: 443"
          else
            # Fallback to NodePort if pod IP isn't available
            echo "Forward Hostname/IP: 127.0.0.1"
            echo "Forward Port: 32443"
          fi

          echo "Enable WebSockets: Yes"
          echo "SSL: Enabled with Let's Encrypt"
          echo "::endgroup::"
